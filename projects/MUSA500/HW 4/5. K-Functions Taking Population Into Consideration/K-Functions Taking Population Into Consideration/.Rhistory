myCorpus <- tm_map(myCorpus, stripWhitespace)
#Stemming (i.e., removing common word endings like "es", "ed", etc.)
myCorpus <- tm_map(myCorpus, stemDocument)
#Creating a Document Term Matrix
dtm <- DocumentTermMatrix(myCorpus)
dtm
dim(dtm)
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
wordcloud(names(freq), freq, min.freq=50, colors=brewer.pal(6, "Dark2"))
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords,c("http", "qhb..." "gazayearon", "https", "amp", "tco", "http...", "for"))
myCorpus <- tm_map(myCorpus, removeWords,c("http", "qhb...", "gazayearon", "https", "amp", "tco", "http...", "for"))
#Removing whitespace characters
#When rendered, a whitespace character does not correspond to a visible
#mark, but typically does occupy an area on a page
myCorpus <- tm_map(myCorpus, stripWhitespace)
#Stemming (i.e., removing common word endings like "es", "ed", etc.)
myCorpus <- tm_map(myCorpus, stemDocument)
#Creating a Document Term Matrix
dtm <- DocumentTermMatrix(myCorpus)
dtm
dim(dtm)
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
wordcloud(names(freq), freq, min.freq=50, colors=brewer.pal(6, "Dark2"))
myCorpus <- tm_map(myCorpus, removeWords,c("http", "qhb...", "gazayearon", "https", "amp", "tco", "http...", "for"))
as.data.frame(myCorpus) %>%
with(., invisible(sapply(text, function(x) {strWrap(x); cat("\n\n")})))
#Removing whitespace characters
#When rendered, a whitespace character does not correspond to a visible
#mark, but typically does occupy an area on a page
myCorpus <- tm_map(myCorpus, stripWhitespace)
#Stemming (i.e., removing common word endings like "es", "ed", etc.)
myCorpus <- tm_map(myCorpus, stemDocument)
#Creating a Document Term Matrix
dtm <- DocumentTermMatrix(myCorpus)
dtm
dim(dtm)
dtm <- DocumentTermMatrix(myCorpus)
myCorpus <- Corpus(VectorSource(df$text));
myCorpus
#Defining toSpace function
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
myCorpus <- tm_map(myCorpus, toSpace, "/|@|\\|")
myCorpus <- tm_map(myCorpus, toSpace, "\\[")
myCorpus <- tm_map(myCorpus, toSpace, "]")
#Removing numbers
myCorpus <- tm_map(myCorpus, removeNumbers)
#Removing punctuation
myCorpus <- tm_map(myCorpus, removePunctuation)
#Removing English stop words
stopwords("english")
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
#Removing our own stop words
myCorpus <- tm_map(myCorpus, removeWords,c("http", "qhb...", "gazayearon", "https", "amp", "tco", "http...", "for"))
#Removing whitespace characters
#When rendered, a whitespace character does not correspond to a visible
#mark, but typically does occupy an area on a page
myCorpus <- tm_map(myCorpus, stripWhitespace)
#Stemming (i.e., removing common word endings like "es", "ed", etc.)
myCorpus <- tm_map(myCorpus, stemDocument)
#Creating a Document Term Matrix
dtm <- DocumentTermMatrix(myCorpus)
dtm
dim(dtm)
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
wordcloud(names(freq), freq, min.freq=50, colors=brewer.pal(6, "Dark2"))
library(graphics)
library(maptools)
library(spatstat)
library(sp)
library(fossil)
library(spatial)
library(adehabitatHR)
library(gdata)
library(raster)
library(rgdal)
library(geostatsp)
#K-FUNCTIONS
#What about K-functions? Of course we'll do K-functions as well!
#Setting working directory
setwd("C:/Users/Pavel/Dropbox/Documents/Work and School/Teaching/CPLN 671 - Statistics and Data Mining/Point Pattern Analysis/Data/K-Functions Taking Population Into Consideration")
r <- raster("C:/Users/Pavel/Dropbox/Documents/Work and School/Teaching/CPLN 671 - Statistics and Data Mining/Point Pattern Analysis/Data/K-Functions Taking Population Into Consideration/popraster")
#rasterimage <- as.im(X="r", W=BoundaryPolygonsOW)
plot(r)
?as
See this example:
library(sp)
library(rgdal)
library(maptools)
library(spatstat)
# read external grid with rgdal; for example this data on package sp
x <- readGDAL("popraster")
#transform to "im" format of spatstat
x.im<- as(x, "im")
library(rgdal)
x.im<- rgdal::as(r, "im")
x.im <- as(r, "im")
x <- readGDAL("r")
x <- readGDAL("popraster")
plot(x)
x.im <- as(r, "im")
x <- readGDAL("popraster")
#transform to "im" format of spatstat
x.im<- as(x, "im")
plot(x.im)
Kinhom(pp,lambda=x.im,correction="Ripley")
#What about K-functions? Of course we'll do K-functions as well!
#Setting working directory
setwd("C:/Users/Pavel/Dropbox/Documents/Work and School/Teaching/CPLN 671 - Statistics and Data Mining/Point Pattern Analysis/Data/K-Functions Taking Population Into Consideration")
r <- raster("C:/Users/Pavel/Dropbox/Documents/Work and School/Teaching/CPLN 671 - Statistics and Data Mining/Point Pattern Analysis/Data/K-Functions Taking Population Into Consideration/popraster")
#rasterimage <- as.im(X="r", W=BoundaryPolygonsOW)
plot(r)
#Reading Polygon Boundary.shp from the directory above
Boundary <- readShapePoly("PA_Albers.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
#Plotting the Boundary Window
plot(r)
title(main = "Point Pattern Analysis")
plot(BoundaryPolygonsOW,add=T)
#Reading in the file with the points
Pts <- read.table("Hospitals_for_R.txt", header=T, sep="\t", colClasses = c("X"="double"))
#Very roughly speaking, using attach() in R is like relying on the implicit use of the
#most recent data set.
#http://www.r-bloggers.com/to-attach-or-not-attach-that-is-the-question/
#Only attach file once. If you do it more than once, use detach(Pts) command 1+ times
#to detach file
#attach(Pts)
#detach(Pts)
pp <- ppp(Pts$X, Pts$Y, window=BoundaryPolygonsOW)
#If the following error message is received: data contain duplicated points
#Use the command duplicated(X,Y) to see which points are duplicates.
#The command cbind(Pts,duplicated(X,Y)) will show you which points have duplicated values
#In general, unless you know that the duplicates shouldn't be there, you would ignore
#this warning.
#Now let's plot the points and the Boundary.
plot(pp,add=T)
title(main = "Point Pattern Analysis")
Kinhom(pp,lambda=x.im,correction="Ripley")
plot(Kinhom(pp,x.im,correction="Ripley"))
Envelopes <- spatstat::envelope(pp, Kinhom, lambda=x.im, nsim=9, correction="Ripley")
plot(Envelopes)
Envelopes <- spatstat::envelope(pp, Kinhom, lambda=x.im, nsim=9, correction="Ripley")
View(Envelopes)
View(Envelopes)
#Setting working directory
setwd("C:/Users/pavel/Dropbox/Documents/Work and School/Teaching/CPLN 671 - Statistics and Data Mining/Point Pattern Analysis/Data/Quadrat Analysis Data")
#Reading Polygon Boundary.shp from the directory above
Boundary <- readShapePoly("Boundary.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
#Plotting the Boundary Window
plot(BoundaryPolygonsOW)
title(main = "Point Pattern Analysis")
#Reading in the file with the points
Pts <- read.table("Quadrat Points.txt", header=T, sep="\t", colClasses = c("X"="double"))
#Very roughly speaking, using attach() in R is like relying on the implicit use of the
#most recent data set.
#http://www.r-bloggers.com/to-attach-or-not-attach-that-is-the-question/
#Only attach file once. If you do it more than once, use detach(Pts) command 1+ times
#to detach file
#attach(Pts)
#detach(Pts)
pp <- ppp(Pts$X, Pts$Y, window=BoundaryPolygonsOW)
#If the following error message is received: data contain duplicated points
#Use the command duplicated(X,Y) to see which points are duplicates.
#The command cbind(Pts,duplicated(X,Y)) will show you which points have duplicated values
#In general, unless you know that the duplicates shouldn't be there, you would ignore
#this warning.
#Now let's plot the points and the Boundary.
plot(pp)
title(main = "Point Pattern Analysis")
#In the slides, we figured out that the approximate length of each quadrat (cell) should be
#274 ft. This implies that we can get 9 quadrats in the horizontal direction and 6 in the
#vertical (we can measure the width and length of the boundary and see that this is true.)
q <- quadratcount(pp, 9,6)
plot(q)
plot(pp, add=T)
quadrat.test(pp, 9, 6)
qmatrix <-table(q)
#http://www.usna.edu/Users/math/jager/courses/sm439/labs/Lab5.pdf
#x is the observed number of points per quadrat
x <- matrix(as.numeric(rownames(qmatrix)))
#frequency is the number of times each observed number of points per quadrat appears
frequency <-matrix(t(qmatrix))
#Total points (i.e., how many total points are there in all quadrats with x points)
totalpoints <-x*frequency
#Observed proportion of all quadrats containing x points. Here,  54 is the number of quadrats.
obsprop <-frequency/54
#Expected proportion of all quadrats containing x points under CSR.
#. This is simply the Poisson CMF with lambda = 100/54.
expprop <- exp(-100/54)*((100/54)^x)/factorial(x)
#Cumulative proportions
#cumsum is a convenient command which does a cumulative (i.e., running) sums of all previous entries
obscumprop <-cumsum(obsprop)
#This is the Poisson CMF. Here, 100 is the number of points and 54 is the number of quadrats.
expcumprop <-ppois(x, lambda=(100/54))
#Absolute difference between expected and observed cumulative proportions
#Notice that the maximum cumdiff value is the same as in Excel, 0.1537.
cumdiff <- round(abs(expcumprop-obscumprop),4)
dataset <-cbind(x,frequency,totalpoints,obsprop,expprop,obscumprop,expcumprop,cumdiff)
#Run the Kolmogorov-Smirnov (K-S) Test. You will notice that the test statistic,
#D, is 0.1429, which is different from the value of 0.1537 above. This is because
#0.1537 is an approximation. And in general, keep in mind that the K-S test was
#really designed for continuous distributions, and we're using it for the
#Poisson distribution, which is discrete.
ks.test(obscumprop,expcumprop)
#NEAREST NEIGHBOR ANALYSIS
#Now let's try some Nearest Neighbor Analysis!
dev.off()
#Computes the distance from each point to its nearest neighbour in a point pattern.
nnd <- nndist.ppp(pp)
#Using the formulas on the slides, we calculate Mean Observed Distance,
#Mean Expected Distance and the Standard Error.
MeanObsDist <- mean(nnd)
#The area.owin command calculates the area of the study area that you use.
#Here it's the minimum enclosing rectangle, but it doesn't have to be - it
#could be any shapefile you import from ArcGIS (or generate in R) that
#corresponds to the study area.
MeanExpDist <- 0.5 / sqrt(nrow(Pts) / area.owin(BoundaryPolygonsOW))
SE <- 0.26136 / sqrt(nrow(Pts)*nrow(Pts) / area.owin(BoundaryPolygonsOW))
#Calculating the z-score
zscore <- (MeanObsDist - MeanExpDist)/SE
#Statistical test
#Here, if the z score is positive, we do an upper-tailed test and if the
#z score is negative we do a lower-tailed test to come up with the p-value.
pval<-ifelse(zscore > 0, 1 - pnorm(zscore), pnorm(zscore))
#Calculating the NNI
NNI <-mnnd / exp_nnd
NNI <- MeanObsDist / MeanExpDist
NNI
zscore
pval
#Reading Polygon Boundary.shp from the directory above
Boundary <- readShapePoly("PA_Albers.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
#Plotting the Boundary Window
plot(r)
title(main = "Point Pattern Analysis")
plot(BoundaryPolygonsOW,add=T)
#Reading in the file with the points
Pts <- read.table("Hospitals_for_R.txt", header=T, sep="\t", colClasses = c("X"="double"))
#Very roughly speaking, using attach() in R is like relying on the implicit use of the
#most recent data set.
#http://www.r-bloggers.com/to-attach-or-not-attach-that-is-the-question/
#Only attach file once. If you do it more than once, use detach(Pts) command 1+ times
#to detach file
#attach(Pts)
#detach(Pts)
pp <- ppp(Pts$X, Pts$Y, window=BoundaryPolygonsOW)
#If the following error message is received: data contain duplicated points
#Use the command duplicated(X,Y) to see which points are duplicates.
#The command cbind(Pts,duplicated(X,Y)) will show you which points have duplicated values
#In general, unless you know that the duplicates shouldn't be there, you would ignore
#this warning.
#Now let's plot the points and the Boundary.
plot(pp,add=T)
title(main = "Point Pattern Analysis")
#Reading Polygon Boundary.shp from the directory above
Boundary <- readShapePoly("PA_Albers.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
#Plotting the Boundary Window
#plot(r)
title(main = "Point Pattern Analysis")
plot(BoundaryPolygonsOW,add=T)
#Reading in the file with the points
Pts <- read.table("Hospitals_for_R.txt", header=T, sep="\t", colClasses = c("X"="double"))
#Very roughly speaking, using attach() in R is like relying on the implicit use of the
#most recent data set.
#http://www.r-bloggers.com/to-attach-or-not-attach-that-is-the-question/
#Only attach file once. If you do it more than once, use detach(Pts) command 1+ times
#to detach file
#attach(Pts)
#detach(Pts)
pp <- ppp(Pts$X, Pts$Y, window=BoundaryPolygonsOW)
#If the following error message is received: data contain duplicated points
#Use the command duplicated(X,Y) to see which points are duplicates.
#The command cbind(Pts,duplicated(X,Y)) will show you which points have duplicated values
#In general, unless you know that the duplicates shouldn't be there, you would ignore
#this warning.
#Now let's plot the points and the Boundary.
plot(pp,add=T)
title(main = "Point Pattern Analysis")
setwd("C:/Users/Pavel/Dropbox/Documents/Work and School/Teaching/CPLN 671 - Statistics and Data Mining/Point Pattern Analysis/Data/K-Functions Taking Population Into Consideration")
#Reading Polygon Boundary.shp from the directory above
Boundary <- readShapePoly("PA_Albers.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
Boundary <- readShapePoly("PA_Albers.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
#Plotting the Boundary Window
#plot(r)
title(main = "Point Pattern Analysis")
plot(BoundaryPolygonsOW,add=T)
#Reading in the file with the points
Pts <- read.table("Hospitals_for_R.txt", header=T, sep="\t", colClasses = c("X"="double"))
plot(BoundaryPolygonsOW,add=T)
title(main = "Point Pattern Analysis")
plot(BoundaryPolygonsOW)#,add=T)
title(main = "Point Pattern Analysis")
#Reading in the file with the points
Pts <- read.table("Hospitals_for_R.txt", header=T, sep="\t", colClasses = c("X"="double"))
pp <- ppp(Pts$X, Pts$Y, window=BoundaryPolygonsOW)
#If the following error message is received: data contain duplicated points
#Use the command duplicated(X,Y) to see which points are duplicates.
#The command cbind(Pts,duplicated(X,Y)) will show you which points have duplicated values
#In general, unless you know that the duplicates shouldn't be there, you would ignore
#this warning.
#Now let's plot the points and the Boundary.
plot(pp,add=T)
title(main = "Point Pattern Analysis")
r <- raster("C:/Users/Pavel/Dropbox/Documents/Work and School/Teaching/CPLN 671 - Statistics and Data Mining/Point Pattern Analysis/Data/K-Functions Taking Population Into Consideration/popraster")
#rasterimage <- as.im(X="r", W=BoundaryPolygonsOW)
plot(r)
#Reading Polygon Boundary.shp from the directory above
Boundary <- readShapePoly("PA_Albers.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
#Plotting the Boundary Window
#plot(r)
plot(BoundaryPolygonsOW,add=T)
title(main = "Point Pattern Analysis")
#Reading in the file with the points
Pts <- read.table("Hospitals_for_R.txt", header=T, sep="\t", colClasses = c("X"="double"))
#Very roughly speaking, using attach() in R is like relying on the implicit use of the
#most recent data set.
#http://www.r-bloggers.com/to-attach-or-not-attach-that-is-the-question/
#Only attach file once. If you do it more than once, use detach(Pts) command 1+ times
#to detach file
#attach(Pts)
#detach(Pts)
pp <- ppp(Pts$X, Pts$Y, window=BoundaryPolygonsOW)
#If the following error message is received: data contain duplicated points
#Use the command duplicated(X,Y) to see which points are duplicates.
#The command cbind(Pts,duplicated(X,Y)) will show you which points have duplicated values
#In general, unless you know that the duplicates shouldn't be there, you would ignore
#this warning.
#Now let's plot the points and the Boundary.
plot(pp,add=T)
title(main = "Point Pattern Analysis")
#Reading Polygon Boundary.shp from the directory above
Boundary <- readShapePoly("PA_Albers.shp")
#Class "SpatialPolygons" holds polygon topology (without attributes)
BoundaryPolygons <- as(Boundary, "SpatialPolygons")
#The class "owin" is a way of specifying the observation window for a point pattern.
BoundaryPolygonsOW<- as(BoundaryPolygons, "owin")
#Plotting the Boundary Window
#plot(r)
plot(BoundaryPolygonsOW)#,add=T)
title(main = "Point Pattern Analysis")
#Reading in the file with the points
Pts <- read.table("Hospitals_for_R.txt", header=T, sep="\t", colClasses = c("X"="double"))
#Very roughly speaking, using attach() in R is like relying on the implicit use of the
#most recent data set.
#http://www.r-bloggers.com/to-attach-or-not-attach-that-is-the-question/
#Only attach file once. If you do it more than once, use detach(Pts) command 1+ times
#to detach file
#attach(Pts)
#detach(Pts)
pp <- ppp(Pts$X, Pts$Y, window=BoundaryPolygonsOW)
#If the following error message is received: data contain duplicated points
#Use the command duplicated(X,Y) to see which points are duplicates.
#The command cbind(Pts,duplicated(X,Y)) will show you which points have duplicated values
#In general, unless you know that the duplicates shouldn't be there, you would ignore
#this warning.
#Now let's plot the points and the Boundary.
plot(pp,add=T)
title(main = "Point Pattern Analysis")
#http://www.math.umt.edu/graham/stat544/ripleys.pdf
#If we double click on the khat data set on the right, it will have 513 observations
#and 5 variables. We are interested in 2 of the variables:
#-- r, which is the distance that goes in increments of 138.8693
#-- iso, which is the k-function calculated with Ripley's edge correction
#K-Functions
khat <-Kest(pp) #,correction="Ripley")
#Plots Ripley’s K function calculated with Ripley’s isotropic edge correction, with
#line width 2, axis labels, and a main title.
plot(khat$r,khat$iso,xlab="r", ylab="Ripley’s K",
main="Ripley’s Estimated K-Function",
cex.lab=1.6,cex.axis=1.5,cex.main=1.5,lty=1,lwd=2)
# Overlays the theoretical K-function under CSR with a dashed (lty=8) line.
lines(khat$r,khat$theo,lty=8, lwd=2)
#Code to compute the Ripley’s Simulation Confidence Envelopes
#Computes confidence envelopes using n=199 simulations. Here, nrank=1 means we're
#looking at the lowest and highest values of the simulated envelopes. Here,
#alpha = 2 * nrank/(1 + nsim) = 2*1/200 = 0.01
#spatstat::envelope is to specify that the envelope command is in the spatstat
#library and not the boot library.
Kenv <- spatstat::envelope(pp,fun="Kest", nsim=199, nrank=1)
# Plots Ripley’s K function with 99% simulation # envelopes, axis labels, and a title.
plot(Kenv,xlab="r",ylab="Khat(r)", cex.lab=1.6,cex.axis=1.5,main=
"Ripley’s Khat with Confidence Envelopes",cex.main=1.5,lwd=2)
#L-Functions
#Computes Ripley’s L* for each sample event
lhat <- Lest(pp)
#Plots Ripley’s L function calculated with line width 2,
#Ripley’s isotropic edge correction, with axis labels, and a main title.
plot(lhat$r,lhat$iso-lhat$r, xlab="r",ylab="Ripley’s L",cex.lab=1.6,
cex.axis=1.5,cex.main=1.5,lty=1,lwd=2, main="Ripley’s Estimated L-Function")
#Overlays the theoretical L-function under CSR with a dashed (lty=8) line.
lines(lhat$r,lhat$theo-lhat$r,lty=8,lwd=2)
#Code to compute the Ripley’s Simulation Confidence Envelopes
#Computes confidence envelopes using n=199 simulations. Here, nrank=1 means we're
#looking at the lowest and highest values of the simulated envelopes. Here,
#alpha = 2 * nrank/(1 + nsim) = 2*1/200 = 0.01
Lenv <- spatstat::envelope(pp,fun="Lest", nsim=199,nrank=1)
# Plots Ripley’s L function with 99% simulation envelopes, axis labels, and a title.
plot(Lenv,xlab="r",ylab="Lhat(r)", cex.lab=1.6,cex.axis=1.5,
main= "Ripley’s Lhat with Confidence Envelopes",cex.main=1.5,lwd=2,legend=F)
#A better way to view this is to rotate this plot 45 degrees clockwise.
#Gives the Ripley’s data frame a new name L2.
L2 <- Lenv
#Now we will subtract the distance r from the R-defined Ripley's L's
#(This will be done for the observed L, theoretical L, lower and uper envelopes)
L2$obs <- L2$obs-L2$r
L2$theo <- L2$theo-L2$r
L2$lo <- L2$lo-L2$r
L2$hi <- L2$hi-L2$r
# Plots Ripley’s L function with 99% simulation envelopes, axis labels, and a title.
plot(L2,xlab="r",ylab="Lhat(r)", cex.lab=1.6,cex.axis=1.5,
main= "Ripley’s Lhat with Confidence Envelopes",cex.main=1.5,lwd=2,legend=F)
?Kest
khat <-Kest(pp, rmax=250000) #,correction="Ripley")
#Plots Ripley’s K function calculated with Ripley’s isotropic edge correction, with
#line width 2, axis labels, and a main title.
plot(khat$r,khat$iso,xlab="r", ylab="Ripley’s K",
main="Ripley’s Estimated K-Function",
cex.lab=1.6,cex.axis=1.5,cex.main=1.5,lty=1,lwd=2)
# Overlays the theoretical K-function under CSR with a dashed (lty=8) line.
lines(khat$r,khat$theo,lty=8, lwd=2)
#Code to compute the Ripley’s Simulation Confidence Envelopes
#Computes confidence envelopes using n=199 simulations. Here, nrank=1 means we're
#looking at the lowest and highest values of the simulated envelopes. Here,
#alpha = 2 * nrank/(1 + nsim) = 2*1/200 = 0.01
#spatstat::envelope is to specify that the envelope command is in the spatstat
#library and not the boot library.
Kenv <- spatstat::envelope(pp,fun="Kest", nsim=199, nrank=1)
# Plots Ripley’s K function with 99% simulation # envelopes, axis labels, and a title.
plot(Kenv,xlab="r",ylab="Khat(r)", cex.lab=1.6,cex.axis=1.5,main=
"Ripley’s Khat with Confidence Envelopes",cex.main=1.5,lwd=2)
khat <-Kest(pp, rmax=250000) #,correction="Ripley")
View(khat)
View(khat)
plot(khat$r,khat$iso,xlab="r", ylab="Ripley’s K",
main="Ripley’s Estimated K-Function",
cex.lab=1.6,cex.axis=1.5,cex.main=1.5,lty=1,lwd=2)
# Overlays the theoretical K-function under CSR with a dashed (lty=8) line.
lines(khat$r,khat$theo,lty=8, lwd=2)
?Kenv
?envelope
Kenv <- spatstat::envelope(pp,fun="Kest", nsim=9, nrank=1)
# Plots Ripley’s K function with 99% simulation # envelopes, axis labels, and a title.
View(Kenv)
View(Kenv)
View(Kenv)
Kest
envelope
View(Kenv)
View(Kenv)
View(khat)
View(khat)
khat <-Kest(pp, rmax=250000) #,correction="Ripley")
#Plots Ripley’s K function calculated with Ripley’s isotropic edge correction, with
#line width 2, axis labels, and a main title.
plot(khat$r,khat$iso,xlab="r", ylab="Ripley’s K",
main="Ripley’s Estimated K-Function",
cex.lab=1.6,cex.axis=1.5,cex.main=1.5,lty=1,lwd=2)
# Overlays the theoretical K-function under CSR with a dashed (lty=8) line.
lines(khat$r,khat$theo,lty=8, lwd=2)
Kenv <- spatstat::envelope(pp,fun="Kest", rmax=250000, nsim=9, nrank=1)
plot(Kenv,xlab="r",ylab="Khat(r)", cex.lab=1.6,cex.axis=1.5,main=
"Ripley’s Khat with Confidence Envelopes",cex.main=1.5,lwd=2)
lhat <- Lest(pp, rmax=250000)
plot(lhat$r,lhat$iso-lhat$r, xlab="r",ylab="Ripley’s L",cex.lab=1.6,
cex.axis=1.5,cex.main=1.5,lty=1,lwd=2, main="Ripley’s Estimated L-Function")
#Overlays the theoretical L-function under CSR with a dashed (lty=8) line.
lines(lhat$r,lhat$theo-lhat$r,lty=8,lwd=2)
#Code to compute the Ripley’s Simulation Confidence Envelopes
#Computes confidence envelopes using n=199 simulations. Here, nrank=1 means we're
#looking at the lowest and highest values of the simulated envelopes. Here,
#alpha = 2 * nrank/(1 + nsim) = 2*1/200 = 0.01
Lenv <- spatstat::envelope(pp,fun="Lest", nsim=199,nrank=1)
Lenv <- spatstat::envelope(pp,fun="Lest", rmax=250000, nsim=9,nrank=1)
plot(Lenv,xlab="r",ylab="Lhat(r)", cex.lab=1.6,cex.axis=1.5,
main= "Ripley’s Lhat with Confidence Envelopes",cex.main=1.5,lwd=2,legend=F)
L2 <- Lenv
#Now we will subtract the distance r from the R-defined Ripley's L's
#(This will be done for the observed L, theoretical L, lower and uper envelopes)
L2$obs <- L2$obs-L2$r
L2$theo <- L2$theo-L2$r
L2$lo <- L2$lo-L2$r
L2$hi <- L2$hi-L2$r
# Plots Ripley’s L function with 99% simulation envelopes, axis labels, and a title.
plot(L2,xlab="r",ylab="Lhat(r)", cex.lab=1.6,cex.axis=1.5,
main= "Ripley’s Lhat with Confidence Envelopes",cex.main=1.5,lwd=2,legend=F)
